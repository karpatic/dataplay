{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Data\n",
    "\n",
    "> This notebook was made to demonstrate how to merge datasets by matching a single columns values from two datasets. We add columns of data from a foreign dataset into the ACS data we downloaded in our last tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Coding Notebook is the __second__ in a series.\n",
    "\n",
    "An Interactive version can be found here <a href=\"https://colab.research.google.com/github/BNIA/colabs/blob/master/02_Merge_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "This colab and more can be found at https://github.com/BNIA/colabs\n",
    "\n",
    "- Content covered in previous tutorials will be used in later tutorials. \n",
    "\n",
    "- __New code and or  information *should* have explanations and or descriptions__ attached. \n",
    "\n",
    "- Concepts or code covered in previous tutorials will be used without being explaining in entirety.\n",
    "\n",
    "- __If content can not be found in the current tutorial and is not covered in previous tutorials, please let me know.__\n",
    "\n",
    "- This notebook has been optimized for Google Colabs ran on a Chrome Browser. \n",
    "\n",
    "- Statements found in the index page on view expressed, responsibility, errors and ommissions, use at risk, and licensing  extend throughout the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Tutorial: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whats Inside?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __The Tutorial__\n",
    "\n",
    "In this notebook, the basics of how to perform a merge are introduced.\n",
    "\n",
    "- We will merge two datasets\n",
    "- We will merge two datasets using a crosswalk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Objectives__\n",
    "\n",
    "By the end of this tutorial users should have an understanding of:\n",
    "- How dataset merges are performed\n",
    "- The types different union approaches a merge can take\n",
    "- The 'mergeData' function, and how to use it in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install these libraries onto the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.0)\n",
      "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.13.post1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.5)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (2.6.1.post1)\n",
      "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.12.0)\n",
      "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.5.0)\n",
      "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n",
      "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
      "Requirement already satisfied: dataplay in /usr/local/lib/python3.6/dist-packages (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas\n",
    "!pip install dataplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run: Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/dataplay/acsDownload.py:27: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n",
      "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "# @title Run: Import Modules\n",
    "\n",
    "# These imports will handle everything\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataplay.acsDownload import retrieve_acs_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "pd.set_option('max_colwidth', 20)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Local File Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing we havent already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# (Optional) Run this cell to gain access to Google Drive (Colabs only) \n",
    "from google.colab import drive\n",
    "\n",
    "# Colabs operates in a virtualized enviornment\n",
    "# Colabs default directory is at ~/content.\n",
    "# We mount Drive into a temporary folder at '~/content/drive' \n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Once connected, I navigate to where the data lives in my drive folder.\n",
    "\n",
    "!cd ./drive/'My Drive'/colabs/DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example will merge two simple datasets; pulling CSA names using tract ID's.\n",
    "\n",
    "The __First__ dataset will be obtained from the Census' ACS 5-year serveys. \n",
    "\n",
    "Functions used to obtain this data were obtained from Tutorial 0) ACS: Explore and Download. \n",
    "\n",
    "The __Second__ dataset will be obtained using using a CSV from a publicly accessible link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Principal dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the function we created in our last tutorial to download the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our download function will use Baltimore City's tract, county and state as internal paramters\n",
    "# Change these values in the cell below using different geographic reference codes will change those parameters\n",
    "tract = '*'\n",
    "county = '510'\n",
    "state = '24'\n",
    "\n",
    "# Specify the download parameters the function will receieve here\n",
    "tableId = 'B19001'\n",
    "year = '17'\n",
    "saveAcs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19001_001E_Total</th>\n",
       "      <th>B19001_002E_Total_Less_than_$10_000</th>\n",
       "      <th>B19001_003E_Total_$10_000_to_$14_999</th>\n",
       "      <th>B19001_004E_Total_$15_000_to_$19_999</th>\n",
       "      <th>B19001_005E_Total_$20_000_to_$24_999</th>\n",
       "      <th>B19001_006E_Total_$25_000_to_$29_999</th>\n",
       "      <th>B19001_007E_Total_$30_000_to_$34_999</th>\n",
       "      <th>B19001_008E_Total_$35_000_to_$39_999</th>\n",
       "      <th>B19001_009E_Total_$40_000_to_$44_999</th>\n",
       "      <th>B19001_010E_Total_$45_000_to_$49_999</th>\n",
       "      <th>B19001_011E_Total_$50_000_to_$59_999</th>\n",
       "      <th>B19001_012E_Total_$60_000_to_$74_999</th>\n",
       "      <th>B19001_013E_Total_$75_000_to_$99_999</th>\n",
       "      <th>B19001_014E_Total_$100_000_to_$124_999</th>\n",
       "      <th>B19001_015E_Total_$125_000_to_$149_999</th>\n",
       "      <th>B19001_016E_Total_$150_000_to_$199_999</th>\n",
       "      <th>B19001_017E_Total_$200_000_or_more</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Census Tract 1901</th>\n",
       "      <td>796</td>\n",
       "      <td>237</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Census Tract 1902</th>\n",
       "      <td>695</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>113</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Census Tract 2201</th>\n",
       "      <td>2208</td>\n",
       "      <td>137</td>\n",
       "      <td>229</td>\n",
       "      <td>124</td>\n",
       "      <td>52</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>66</td>\n",
       "      <td>159</td>\n",
       "      <td>205</td>\n",
       "      <td>167</td>\n",
       "      <td>146</td>\n",
       "      <td>398</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Census Tract 2303</th>\n",
       "      <td>632</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>98</td>\n",
       "      <td>111</td>\n",
       "      <td>63</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>230300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Census Tract 2502.07</th>\n",
       "      <td>836</td>\n",
       "      <td>102</td>\n",
       "      <td>28</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>250207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      B19001_001E_Total  B19001_002E_Total_Less_than_$10_000  B19001_003E_Total_$10_000_to_$14_999  B19001_004E_Total_$15_000_to_$19_999  B19001_005E_Total_$20_000_to_$24_999  B19001_006E_Total_$25_000_to_$29_999  B19001_007E_Total_$30_000_to_$34_999  B19001_008E_Total_$35_000_to_$39_999  B19001_009E_Total_$40_000_to_$44_999  B19001_010E_Total_$45_000_to_$49_999  B19001_011E_Total_$50_000_to_$59_999  B19001_012E_Total_$60_000_to_$74_999  B19001_013E_Total_$75_000_to_$99_999  B19001_014E_Total_$100_000_to_$124_999  B19001_015E_Total_$125_000_to_$149_999  B19001_016E_Total_$150_000_to_$199_999  B19001_017E_Total_$200_000_or_more  state  county   tract\n",
       "NAME                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "Census Tract 1901                   796                  237                                   76                                    85                                    38                                    79                                    43                                    36                                    35                                    15                                    43                                    45                                    39                                     5                                       0                                       6                                      14                    24     510  190100\n",
       "Census Tract 1902                   695                   63                                   87                                    93                                     6                                    58                                    30                                    14                                    29                                    23                                    38                                   113                                    70                                     6                                      32                                      11                                      22                    24     510  190200\n",
       "Census Tract 2201                  2208                  137                                  229                                   124                                    52                                    78                                    87                                    50                                    80                                    13                                   217                                    66                                   159                                   205                                     167                                     146                                     398                    24     510  220100\n",
       "Census Tract 2303                   632                    3                                   20                                     0                                    39                                     7                                     0                                    29                                     8                                     9                                    44                                    29                                    98                                   111                                      63                                      94                                      78                    24     510  230300\n",
       "Census Tract 2502.07                836                  102                                   28                                   101                                    64                                   104                                    76                                    41                                    40                                    47                                    72                                    28                                    60                                    19                                      27                                      15                                      12                    24     510  250207"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Secondary Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Spatial data can be attained by using the 2010 Census Tract Shapefile Picking [Tool](https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2010&layergroup=Census+Tracts) or search their website for\n",
    "Tiger/[Line](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2010.html) Shapefiles\n",
    "> The core TIGER/Line Files and Shapefiles do not include demographic data, but they do contain geographic entity codes (GEOIDs) that can be linked to the Census Bureau’s demographic data, available on data.census.gov.-census.gov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundaries Example: https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8xXdUaT17jkdK0MWTJpg3GOy6jMWeaXTlguXNjCSb8Vr_FanSZQRaTU-m811fQz4kyMFK5wcahMNY/pub?gid=886223646&single=true&output=csv\n"
     ]
    }
   ],
   "source": [
    "print('Boundaries Example: https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8xXdUaT17jkdK0MWTJpg3GOy6jMWeaXTlguXNjCSb8Vr_FanSZQRaTU-m811fQz4kyMFK5wcahMNY/pub?gid=886223646&single=true&output=csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tract 2 CSA Crosswalk : https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv\n",
      "\n",
      " Please enter the location of your file : \n",
      "https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRACT2010</th>\n",
       "      <th>GEOID2010</th>\n",
       "      <th>CSA2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10100</td>\n",
       "      <td>24510010100</td>\n",
       "      <td>Canton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10200</td>\n",
       "      <td>24510010200</td>\n",
       "      <td>Patterson Park N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10300</td>\n",
       "      <td>24510010300</td>\n",
       "      <td>Canton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10400</td>\n",
       "      <td>24510010400</td>\n",
       "      <td>Canton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10500</td>\n",
       "      <td>24510010500</td>\n",
       "      <td>Fells Point</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRACT2010    GEOID2010              CSA2010\n",
       "0      10100  24510010100               Canton\n",
       "1      10200  24510010200  Patterson Park N...\n",
       "2      10300  24510010300               Canton\n",
       "3      10400  24510010400               Canton\n",
       "4      10500  24510010500          Fells Point"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Second dataset. \n",
    "# Our Example dataset contains Polygon Geometry information. \n",
    "# We want to merge this over to our principle dataset. \n",
    "# we will grab it by matching on either CSA or Tract\n",
    "\n",
    "# The url listed below is public.\n",
    "\n",
    "print('Tract 2 CSA Crosswalk : https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv')\n",
    "\n",
    "inFile = input(\"\\n Please enter the location of your file : \\n\" )\n",
    "\n",
    "crosswalk = pd.read_csv( inFile )\n",
    "crosswalk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Merge & Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following picture does nothing important but serves as a friendly reminder of the 4 basic join types.\n",
    "\n",
    "<image src=\"https://docs.trifacta.com/download/attachments/123830435/JoinVennDiagram.png\" height='200px'/>\n",
    "\n",
    "- Left - returns all left records, only includes the right record if it has a match\n",
    "- Right - Returns all right records, only includes the left record if it has a match \n",
    "- Full - Returns all records regardless of keys matching\n",
    "- Inner - Returns only records where a key match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Columns from both datasets to match on\n",
    "\n",
    "You can get these values from the column values above.\n",
    "\n",
    "Our Examples will work with the prompted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Princpal Columns Index(['B19001_001E_Total', 'B19001_002E_Total_Less_than_$10_000',\n",
      "       'B19001_003E_Total_$10_000_to_$14_999',\n",
      "       'B19001_004E_Total_$15_000_to_$19_999',\n",
      "       'B19001_005E_Total_$20_000_to_$24_999',\n",
      "       'B19001_006E_Total_$25_000_to_$29_999',\n",
      "       'B19001_007E_Total_$30_000_to_$34_999',\n",
      "       'B19001_008E_Total_$35_000_to_$39_999',\n",
      "       'B19001_009E_Total_$40_000_to_$44_999',\n",
      "       'B19001_010E_Total_$45_000_to_$49_999',\n",
      "       'B19001_011E_Total_$50_000_to_$59_999',\n",
      "       'B19001_012E_Total_$60_000_to_$74_999',\n",
      "       'B19001_013E_Total_$75_000_to_$99_999',\n",
      "       'B19001_014E_Total_$100_000_to_$124_999',\n",
      "       'B19001_015E_Total_$125_000_to_$149_999',\n",
      "       'B19001_016E_Total_$150_000_to_$199_999',\n",
      "       'B19001_017E_Total_$200_000_or_more', 'state', 'county', 'tract'],\n",
      "      dtype='object')\n",
      "Left on principal column: ('tract') \n",
      "tract\n",
      " \n",
      " \n",
      "Crosswalk Columns Index(['TRACT2010', 'GEOID2010', 'CSA2010'], dtype='object')\n",
      "Right on crosswalk column: ('TRACT2010', or, 'TRACTCE10') \n",
      "TRACT2010\n"
     ]
    }
   ],
   "source": [
    "print( 'Princpal Columns ' + str(df.columns) + '')\n",
    "left_on = input(\"Left on principal column: ('tract') \\n\" )\n",
    "print(' \\n ');\n",
    "print( 'Crosswalk Columns ' + str(crosswalk.columns) + '')\n",
    "right_on = input(\"Right on crosswalk column: ('TRACT2010') \\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify how the merge will be performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a left merge in this example.\n",
    "\n",
    "It will return our Principal dataset with columns from the second dataset appended to records where their specified columns match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How: (‘left’, ‘right’, ‘outer’, ‘inner’) inner\n"
     ]
    }
   ],
   "source": [
    "how = input(\"How: (‘left’, ‘right’, ‘outer’, ‘inner’) \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually perfrom the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19001_001E_Total</th>\n",
       "      <th>B19001_002E_Total_Less_than_$10_000</th>\n",
       "      <th>B19001_003E_Total_$10_000_to_$14_999</th>\n",
       "      <th>B19001_004E_Total_$15_000_to_$19_999</th>\n",
       "      <th>B19001_005E_Total_$20_000_to_$24_999</th>\n",
       "      <th>B19001_006E_Total_$25_000_to_$29_999</th>\n",
       "      <th>B19001_007E_Total_$30_000_to_$34_999</th>\n",
       "      <th>B19001_008E_Total_$35_000_to_$39_999</th>\n",
       "      <th>B19001_009E_Total_$40_000_to_$44_999</th>\n",
       "      <th>B19001_010E_Total_$45_000_to_$49_999</th>\n",
       "      <th>B19001_011E_Total_$50_000_to_$59_999</th>\n",
       "      <th>B19001_012E_Total_$60_000_to_$74_999</th>\n",
       "      <th>B19001_013E_Total_$75_000_to_$99_999</th>\n",
       "      <th>B19001_014E_Total_$100_000_to_$124_999</th>\n",
       "      <th>B19001_015E_Total_$125_000_to_$149_999</th>\n",
       "      <th>B19001_016E_Total_$150_000_to_$199_999</th>\n",
       "      <th>B19001_017E_Total_$200_000_or_more</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>TRACT2010</th>\n",
       "      <th>GEOID2010</th>\n",
       "      <th>CSA2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>796</td>\n",
       "      <td>237</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>190100</td>\n",
       "      <td>24510190100</td>\n",
       "      <td>Southwest Baltimore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>695</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>113</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>190200</td>\n",
       "      <td>24510190200</td>\n",
       "      <td>Southwest Baltimore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2208</td>\n",
       "      <td>137</td>\n",
       "      <td>229</td>\n",
       "      <td>124</td>\n",
       "      <td>52</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>13</td>\n",
       "      <td>217</td>\n",
       "      <td>66</td>\n",
       "      <td>159</td>\n",
       "      <td>205</td>\n",
       "      <td>167</td>\n",
       "      <td>146</td>\n",
       "      <td>398</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>220100</td>\n",
       "      <td>24510220100</td>\n",
       "      <td>Inner Harbor/Fed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>632</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>98</td>\n",
       "      <td>111</td>\n",
       "      <td>63</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>230300</td>\n",
       "      <td>24510230300</td>\n",
       "      <td>South Baltimore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>836</td>\n",
       "      <td>102</td>\n",
       "      <td>28</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>250207</td>\n",
       "      <td>24510250207</td>\n",
       "      <td>Cherry Hill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B19001_001E_Total  B19001_002E_Total_Less_than_$10_000  B19001_003E_Total_$10_000_to_$14_999  B19001_004E_Total_$15_000_to_$19_999  B19001_005E_Total_$20_000_to_$24_999  B19001_006E_Total_$25_000_to_$29_999  B19001_007E_Total_$30_000_to_$34_999  B19001_008E_Total_$35_000_to_$39_999  B19001_009E_Total_$40_000_to_$44_999  B19001_010E_Total_$45_000_to_$49_999  B19001_011E_Total_$50_000_to_$59_999  B19001_012E_Total_$60_000_to_$74_999  B19001_013E_Total_$75_000_to_$99_999  B19001_014E_Total_$100_000_to_$124_999  B19001_015E_Total_$125_000_to_$149_999  B19001_016E_Total_$150_000_to_$199_999  B19001_017E_Total_$200_000_or_more  state  county  TRACT2010    GEOID2010              CSA2010\n",
       "0                796                  237                                   76                                    85                                    38                                    79                                    43                                    36                                    35                                    15                                    43                                    45                                    39                                     5                                       0                                       6                                      14                    24     510     190100  24510190100  Southwest Baltimore\n",
       "1                695                   63                                   87                                    93                                     6                                    58                                    30                                    14                                    29                                    23                                    38                                   113                                    70                                     6                                      32                                      11                                      22                    24     510     190200  24510190200  Southwest Baltimore\n",
       "2               2208                  137                                  229                                   124                                    52                                    78                                    87                                    50                                    80                                    13                                   217                                    66                                   159                                   205                                     167                                     146                                     398                    24     510     220100  24510220100  Inner Harbor/Fed...\n",
       "3                632                    3                                   20                                     0                                    39                                     7                                     0                                    29                                     8                                     9                                    44                                    29                                    98                                   111                                      63                                      94                                      78                    24     510     230300  24510230300      South Baltimore\n",
       "4                836                  102                                   28                                   101                                    64                                   104                                    76                                    41                                    40                                    47                                    72                                    28                                    60                                    19                                      27                                      15                                      12                    24     510     250207  24510250207          Cherry Hill"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)\n",
    "merged_df = merged_df.drop(left_on, axis=1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our Census data will now have a CSA appended to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the new Filename to save the data to ('acs_csa_merge_test': asdfadsf\n"
     ]
    }
   ],
   "source": [
    "# Save Data to User Specified File\n",
    "outFile = input(\"Please enter the new Filename to save the data to ('acs_csa_merge_test': \" )\n",
    "merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = input(\"Enter a URL? If not ACS data will be used. (Y/N):  \" )\n",
    "if (flag == 'y' or flag == 'Y'):\n",
    "  df = pd.read_csv( input(\"Please enter the location of your Principal file: \" ) )\n",
    "else:\n",
    "  tract = input(\"Please enter tract id (*): \" )\n",
    "  county = input(\"Please enter county id (510): \" )\n",
    "  state = input(\"Please enter state id (24): \" )\n",
    "  tableId = input(\"Please enter acs table id (B19001): \" ) \n",
    "  year = input(\"Please enter acs year (18): \" )\n",
    "  saveAcs = input(\"Save ACS? (Y/N): \" )\n",
    "  df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n",
    "\n",
    "print( 'Principal Columns ' + str(df.columns))\n",
    "\n",
    "print('Crosswalk Example: https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv')\n",
    "\n",
    "crosswalk = pd.read_csv( input(\"Please enter the location of your crosswalk file: \" ) )\n",
    "print( 'Crosswalk Columns ' + str(crosswalk.columns) + '\\n')\n",
    "\n",
    "left_on = input(\"Left on: \" )\n",
    "right_on = input(\"Right on: \" )\n",
    "how = input(\"How: (‘left’, ‘right’, ‘outer’, ‘inner’) \" )\n",
    "\n",
    "merged_df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)\n",
    "merged_df = merged_df.drop(left_on, axis=1)\n",
    "\n",
    "# Save the data\n",
    "# Save the data\n",
    "saveFile = input(\"Save File ('Y' or 'N'): \")\n",
    "if saveFile == 'Y' or saveFile == 'y':\n",
    "  outFile = input(\"Saved Filename (Do not include the file extension ): \")\n",
    "  merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change some those parameters\n",
    "tract = '*'\n",
    "county = '510'\n",
    "state = '24'\n",
    "\n",
    "# Specify the download parameters the function will receieve here\n",
    "tableId = 'B19001'\n",
    "year = '17'\n",
    "saveAcs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Intro__\n",
    "\n",
    "The following Python function is a bulked out version of the previous notes. \n",
    "- It contains everything from the tutorial plus more.\n",
    "- It can be imported and used in future projects or stand alone.\n",
    "\n",
    "**Description:** add columns of data from a foreign dataset into a primary dataset along set parameters. \n",
    "\n",
    "**Purpose:** Makes Merging datasets simple\n",
    "\n",
    "__Services__\n",
    "\n",
    "- Merge two datasets without a crosswalk\n",
    "- Merge two datasets with a crosswalk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@title Run: Create mergeDatasets()\n",
    "\n",
    "# Geometry_DS = https://docs.google.com/spreadsheets/d/e/2PACX-1vTPKW6YOHPFvkw3FM3m5y67-Aa5ZlrM0Ee1Fb57wlGuldr99sEvVWnkej30FXhSb3j8o9gr8izq2ZRP/pub?output=csv\n",
    "# Data_DS = https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv\n",
    "\n",
    "def mergeDatasets(left_ds=False, \n",
    "                  right_ds=False, \n",
    "                  crosswalk_ds=False, \n",
    "                  use_crosswalk = True,\n",
    "                  left_col=False, \n",
    "                  right_col=False, \n",
    "                  crosswalk_left_col = False, \n",
    "                  crosswalk_right_col = False, \n",
    "                  merge_how=False,\n",
    "                  interactive=True): \n",
    "    \n",
    "  # Decide to perform a merge or commit a pull\n",
    "  def mergeOrPull(df, cw, left_on, right_on, how):  \n",
    "    \n",
    "    def merge(df, cw, left_on, right_on, how):\n",
    "      df = pd.merge(df, cw, left_on=left_on, right_on=right_on, how=how)\n",
    "      # df.drop(left_on, axis=1)\n",
    "      df[right_on] = df[right_on].fillna(value='empty')\n",
    "      return df\n",
    "\n",
    "    def pull(df, cw, left_on, right_on, how):\n",
    "      crswlk = dict(zip(cw[right_on], cw[how]  ) )\n",
    "      dtype = df[left_on].dtype\n",
    "      if dtype =='object':  df[how] = df.apply(lambda row: crswlk.get(str(row[left_on]), \"empty\"), axis=1)\n",
    "      elif dtype == 'int64': \n",
    "        df[how] = df.apply(lambda row: crswlk.get(int(row[left_on]), \"empty\"), axis=1)\n",
    "      return df\n",
    "    \n",
    "    mergeType = how in ['left', 'right', 'outer', 'inner']\n",
    "    if mergeType: return merge(df, cw, left_on, right_on, how)\n",
    "    else: return pull(df, cw, left_on, right_on, how)\n",
    "    \n",
    "  \n",
    "    \n",
    "  # Filter between matched records and not.\n",
    "  def filterEmpties(df, cw, left_on, right_on, how, interactive):\n",
    "    \n",
    "    if how in ['left', 'right', 'outer', 'inner']: how = right_on\n",
    "    nomatch = df.loc[df[how] == 'empty']\n",
    "    nomatch = nomatch.sort_values(by=left_on, ascending=True)\n",
    "    \n",
    "    if nomatch.shape[0] > 0:\n",
    "      # Do the same thing with our foreign tracts\n",
    "      if(interactive): print('\\n Local Column Values Not Matched ')\n",
    "      if(interactive): print(nomatch[left_on].unique() )\n",
    "      if(interactive): print(len(nomatch[left_on]))\n",
    "      if(interactive): print('\\n Crosswalk Unique Column Values')\n",
    "      if(interactive): print(cw[right_on].unique() )\n",
    "    \n",
    "    # Create a new column with the tracts value mapped to its corresponding value from the crossswalk\n",
    "    df[how].replace('empty', np.nan, inplace=True)\n",
    "    df.dropna(subset=[how], inplace=True)\n",
    "    # cw = cw.sort_values(by=how, ascending=True)\n",
    "    return df\n",
    "\n",
    "  # Check Crosswalk Params\n",
    "  def handleCrosswalkDataset(crosswalk_ds, crosswalk_left_col, crosswalk_right_col, interactive):\n",
    "    noDataset = (not isinstance(crosswalk_ds, pd.DataFrame))\n",
    "    noColumns = (not crosswalk_left_col or not crosswalk_right_col)\n",
    "    columnDne = checkColumns(crosswalk_ds, crosswalk_left_col)\n",
    "    columnDne = checkColumns(crosswalk_ds, crosswalk_right_col)\n",
    "    if ( noDataset or noColumns ): return mergeDatasets( *getMergeParams() );\n",
    "\n",
    "\n",
    "\n",
    "  def handleMergeHow(right_ds, merge_how, interactive):\n",
    "    howList = ['left', 'right', 'outer', 'inner'] \n",
    "    mergeHowInHowList = merge_how in howList\n",
    "    mergeHowInRightDf = checkColumns(right_ds, merge_how)\n",
    "    mergeHowExists = (mergeHowInRightDf or mergeHowInHowList)\n",
    "    if ( mergeHowExists ): return merge_how\n",
    "    elif ( not interactive): return False\n",
    "    else: \n",
    "      try: \n",
    "        print('Valid Column Not Given');\n",
    "        print(\"\\n 1) Pull A single Column from the Right Dataset: \", right_ds.columns)\n",
    "        print(\"OR\");\n",
    "        print(\"2) Join Operation: (‘left’, ‘right’, ‘outer’, ‘inner’, columnName) \" )\n",
    "        print(\"\\n Please select a value from either list\");\n",
    "        merge_how = input(\"Column Name: \" )\n",
    "        return handleMergeHow(right_ds, merge_how, interactive);\n",
    "      except: return handleMergeHow(right_ds, merge_how, interactive);\n",
    "\n",
    "\n",
    "\n",
    "  def processColumn(df, col, interactive):\n",
    "    # Check Column in Dataset \n",
    "    colExists = checkColumns(df, col)\n",
    "    noColNotInteractive = not colExists and not interactive\n",
    "    if colExists: return col\n",
    "    elif (noColNotInteractive): return False\n",
    "    else: \n",
    "        try: \n",
    "          print('Valid Column Not Given');\n",
    "          print(df.columns)\n",
    "          print(df.head())\n",
    "          print(\"Please provide a dataset column name from the list above.\");\n",
    "          col = input(\"Column Name: \" )\n",
    "          colExists = checkColumns(df, col)\n",
    "          if (colExists): return col\n",
    "          else: return processColumn(df, col, interactive);\n",
    "        except: return processColumn(df, col, interactive);\n",
    "\n",
    "\n",
    "\n",
    "  # Returns a DF if provided a DF or URL. False otherwise. \n",
    "  def retrieveDatasetFromUrl(df):\n",
    "    datasetExists = checkDataSetExists(df)\n",
    "    urlGiven = df and not datasetExists\n",
    "    if datasetExists: return df\n",
    "    elif ( urlGiven ):\n",
    "      try: \n",
    "        urlGiven = df\n",
    "        df = pd.read_csv( df )\n",
    "        datasetExists = checkDataSetExists(df)\n",
    "        if datasetExists: return df\n",
    "      except: return False;\n",
    "    else: return False\n",
    "\n",
    "  # If !DF and interactive, re-processDataset. False otherwise.\n",
    "  def retrieveUrlForDataset(df, interactive):\n",
    "    dsExists = checkDataSetExists(df)\n",
    "    if( dsExists ): return df\n",
    "    if ( not dsExists and not interactive): return False;\n",
    "    if ( not dsExists and interactive): \n",
    "      df = input(\"Please provide a new dataset URL: \" );\n",
    "      return processDataset(df, interactive)\n",
    "\n",
    "  # Ensures a Pandas DF is returned. \n",
    "  # If not Interactive, may return FALSE.\n",
    "  def processDataset(df, interactive):\n",
    "    # Returns a DF if provided a DF or URL. False otherwise. \n",
    "    df = retrieveDatasetFromUrl(df)\n",
    "    # If !DF and interactive, re-processDataset w/a new URL\n",
    "    df = retrieveUrlForDataset(df, interactive)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Check Dataset Params\n",
    "  def handleDatasetAndColumns(df, col, interactive):\n",
    "    dfStatus = colStatus = True\n",
    "    # Ensure A Dataset is being handled\n",
    "    df = processDataset(df, interactive)\n",
    "    if ( not checkDataSetExists(df) ): dfStatus = False\n",
    "\n",
    "    # Ensure A Column Exists\n",
    "    col = processColumn(df, col, interactive)\n",
    "    if ( col == False ): colStatus = False\n",
    "    return df, col, dfStatus, colStatus\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Ensure data types are the same\n",
    "  def coerceDtypes(left_ds, right_ds, left_col, right_col, interactive):\n",
    "    status = False\n",
    "    foreignDtype = right_ds[right_col].dtype\n",
    "    localDtype = left_ds[left_col].dtype  \n",
    "\n",
    "    localIsNumber = localDtype == 'float64' or localDtype == 'int64'\n",
    "    foreignIsNumber = foreignDtype == 'int64' or foreignDtype == 'int64'\n",
    "\n",
    "    if foreignIsNumber: right_ds[right_col] = right_ds[right_col].fillna(-1321321321321325)\n",
    "    if localIsNumber: left_ds[left_col] = left_ds[left_col].fillna(-1321321321321325)\n",
    "    \n",
    "    # Coerce one way or the other if possible\n",
    "    if localIsNumber and foreignDtype == 'object':\n",
    "      if(interactive): print('Converting Foreign Key from Object to Int' )\n",
    "      right_ds[right_col] = pd.to_numeric(right_ds[right_col], errors='coerce')\n",
    "      \n",
    "    if localDtype == 'object' and foreignIsNumber:\n",
    "      if(interactive):  print('Converting Foreign Key from Object to Int' )\n",
    "      left_ds[left_col] = pd.to_numeric(left_ds[left_col], errors='coerce')\n",
    "\n",
    "    # Coerce INTS AND FLOATS if possible        \n",
    "    if localDtype == 'int64' and foreignDtype == 'float64':\n",
    "      if(interactive): print('Converting Local Key from Int to float' )\n",
    "      right_ds[right_col] = right_ds[right_col].astype(int)\n",
    "\n",
    "    if localDtype == 'float64' and foreignDtype == 'int64':\n",
    "      if(interactive): print('Converting Local Key from float64 to Int' )\n",
    "      left_ds[left_col] = left_ds[left_col].astype(int)\n",
    "\n",
    "    foreignDtype = right_ds[right_col].dtype\n",
    "    localDtype = left_ds[left_col].dtype\n",
    "\n",
    "    # Return the data and the coerce status\n",
    "    if localDtype == foreignDtype: status = True\n",
    "    return left_ds, right_ds, status\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Check if the columns actually exist\n",
    "  def checkColumns(dataset, column): return {column}.issubset(dataset.columns) \n",
    "  # Check if the DataSet actually exist\n",
    "  def checkDataSetExists(df): return isinstance(df, pd.DataFrame)\n",
    "\n",
    "  # This function uses all the other functions\n",
    "  def main(left_ds, right_ds, crosswalk_ds, use_crosswalk, left_col, right_col, \n",
    "           crosswalk_left_col, crosswalk_right_col, merge_how, interactive):\n",
    "    \n",
    "    if(interactive):print('\\n Handling Left Dataset');\n",
    "    left_ds, left_col, dfStatus, colStatus = handleDatasetAndColumns(left_ds, left_col, interactive)\n",
    "    if ( dfStatus and colStatus and interactive):\n",
    "      print('Left Dataset and Columns are Valid');\n",
    "    elif( not (dfStatus and colStatus) and not interactive):\n",
    "      return 'ERROR: Error with Left Dataset and or Column'\n",
    "\n",
    "    if(interactive):print('\\n Handling Right Dataset');\n",
    "    right_ds, right_col, dfStatus, colStatus  = handleDatasetAndColumns(right_ds, right_col, interactive)\n",
    "    if ( dfStatus and colStatus and interactive):\n",
    "      print('Right Dataset and Columns are Valid');\n",
    "    elif( not (dfStatus and colStatus) and not interactive):\n",
    "      return 'ERROR: Error with Right Dataset and or Column'\n",
    "\n",
    "    if(interactive):print('\\n Checking the merge_how Parameter');\n",
    "    merge_how = handleMergeHow(right_ds, merge_how, interactive)\n",
    "    if ( merge_how and interactive): print('merge_how operator is Valid', merge_how)\n",
    "    elif( not  merge_how and not interactive ): return 'ERROR: Error with merge_how Paramter'\n",
    "\n",
    "    # Returns true if a DF. False if URL\n",
    "    crosswalkSupplied = checkDataSetExists(crosswalk_ds)\n",
    "    if not crosswalkSupplied and isinstance(crosswalk_ds, str): crosswalkSupplied = True\n",
    "    if (interactive and use_crosswalk):\n",
    "      if(interactive): print('\\n Checking the Crosswalk Parameter');\n",
    "      if(not crosswalkSupplied):  \n",
    "        use_crosswalk = input(\"Are you using a crosswalk? 'True' or 'False': \" )\n",
    "        use_crosswalk = use_crosswalk == \"True\"\n",
    "    else: use_crosswalk = crosswalkSupplied\n",
    "\n",
    "    # If a user is using a crosswalk, then assess match for left-cw, and right-cw.\n",
    "    if( use_crosswalk ): \n",
    "      # This will load our dataset if provided as a url.\n",
    "      if(interactive):print('\\n Handling Crosswalk Left Dataset Loading');\n",
    "      crosswalk_ds_discard, crosswalk_left_col, dfStatus, colStatus = handleDatasetAndColumns(crosswalk_ds, crosswalk_left_col, interactive)\n",
    "      # the first Item is our Dataset, which we discard the first time this data is called, kept the second.\n",
    "      if(interactive):print('\\n Handling Crosswalk Right Dataset Loading');\n",
    "      crosswalk_ds, crosswalk_right_col, dfStatus, colStatus = handleDatasetAndColumns(crosswalk_ds, crosswalk_right_col, interactive)\n",
    "      if(interactive):print('\\n Assessment Completed');\n",
    "\n",
    "      if(interactive): print('\\n Ensuring Left->Crosswalk compatability')\n",
    "      left_ds, crosswalk_ds, status = coerceDtypes(left_ds, crosswalk_ds, left_col, crosswalk_left_col, interactive);\n",
    "      if(interactive): print('\\n Ensuring Crosswalk->Right compatability')\n",
    "      right_ds, crosswalk_ds, status = coerceDtypes(right_ds, crosswalk_ds, right_col, crosswalk_right_col, interactive);\n",
    "    # If a user is not using a crswk, then assess match for left-right.\n",
    "    else:\n",
    "      if(interactive): print('\\n Ensuring Left->Right compatability')\n",
    "      left_ds, right_ds, status = coerceDtypes(left_ds, right_ds, left_col, right_col, interactive);\n",
    "\n",
    "    if( status == False and not interactive ): \n",
    "      print('ERROR: Foreign keys data types do not match'); \n",
    "      return False;\n",
    "    if( status == False and interactive ):\n",
    "      print('Could not resolve differences in data types.')\n",
    "      restart = input(\"Would you like to restart?: 'True' or 'False': \" )\n",
    "      restart = restart == \"True\"\n",
    "      if restart : return mergeDatasets()\n",
    "      else: print('GOODBYE'); return left_ds, right_ds\n",
    "\n",
    "    else:\n",
    "      if(use_crosswalk): \n",
    "        if(interactive): \n",
    "          print('PERFORMING MERGE LEFT->CROSSWALK');\n",
    "          print('left_on', crosswalk_left_col, 'right_on', crosswalk_right_col, 'how', merge_how); \n",
    "        # Perform the left-CW Merge using left_col, crosswalk_left_col then pull the crosswalk_right_col\n",
    "        left_ds = mergeOrPull(left_ds, crosswalk_ds, left_col, crosswalk_left_col, crosswalk_right_col)   \n",
    "        # Filter out columns not matched\n",
    "        left_ds = filterEmpties(left_ds, crosswalk_ds, left_col, crosswalk_left_col, crosswalk_right_col, interactive)\n",
    "        # set the new left_col as the crosswalk_right_col since it will be able to match to the right_col\n",
    "        left_col = crosswalk_right_col\n",
    "\n",
    "      # If the crosswalk was needed, it has now been integrated in to the left table.\n",
    "      # The crosswalk col corresponding to the right_col should exist in the left Table.\n",
    "      # Merge the left and right tables now.\n",
    "      \n",
    "      if(interactive):\n",
    "        print('PERFORMING MERGE LEFT->RIGHT');\n",
    "        print('left_col', left_col, 'right_col', right_col, 'how', merge_how); \n",
    "      # Perform the merge\n",
    "      left_ds = mergeOrPull(left_ds, right_ds, left_col, right_col, merge_how)   \n",
    "      # Filter out columns not matched\n",
    "      left_ds = filterEmpties(left_ds, right_ds, left_col, right_col, merge_how, interactive)\n",
    "\n",
    "    return left_ds\n",
    "\n",
    "  return main( left_ds, right_ds, crosswalk_ds, use_crosswalk, left_col, right_col, crosswalk_left_col, crosswalk_right_col, merge_how, interactive )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input(s):** \n",
    "- Dataset url\n",
    "- Crosswalk Url \n",
    "- Right On \n",
    "- Left On \n",
    "- How \n",
    "- New Filename \n",
    "\n",
    "**Output:** File\n",
    "\n",
    "**How it works:**\n",
    "- Read in datasets\n",
    "- Perform Merge\n",
    "\n",
    "- If the 'how' parameter is equal to ['left', 'right', 'outer', 'inner']\n",
    "- - then a merge will be performed. \n",
    "- If a column name is provided in the 'how' parameter\n",
    "- - then that single column will be pulled from the right dataset as a new column in the left_ds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram the mergeDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://charleskarpati.com/images/class_diagram_merge_datasets.png\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://charleskarpati.com/images/class_diagram_merge_datasets.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mergeDatasets Flow Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://charleskarpati.com/images/flow_chart_merge_datasets.png\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://charleskarpati.com/images/flow_chart_merge_datasets.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gannt Chart  mergeDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://charleskarpati.com/images/gannt_chart_merge_datasets.png\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://charleskarpati.com/images/gannt_chart_merge_datasets.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence Diagram  mergeDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://charleskarpati.com/images/sequence_diagram_merge_datasets.png\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://charleskarpati.com/images/sequence_diagram_merge_datasets.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Handling Left Dataset\n",
      "Left Dataset and Columns are Valid\n",
      "\n",
      " Handling Right Dataset\n",
      "Right Dataset and Columns are Valid\n",
      "\n",
      " Checking the merge_how Parameter\n",
      "merge_how operator is Valid left\n",
      "\n",
      " Ensuring Left->Right compatability\n",
      "Converting Local Key from float64 to Int\n",
      "PERFORMING MERGE LEFT->RIGHT\n",
      "left_col Census Tract right_col TRACT2010 how left\n",
      "\n",
      " Local Column Values Not Matched \n",
      "[-1321321321321325            400100            401101            401102\n",
      "            401507            403401            403500            403803\n",
      "            411306            411406            411408            420100\n",
      "            420301            420701            420800            430800\n",
      "            430900            440100            440200            440702\n",
      "            441101            450300            452000            490601\n",
      "            490602            491100            491201            491600\n",
      "            492300            750101]\n",
      "43\n",
      "\n",
      " Crosswalk Unique Column Values\n",
      "[ 10100  10200  10300  10400  10500  20100  20200  20300  30100  30200\n",
      "  40100  40200  60100  60200  60300  60400  70100  70200  70300  70400\n",
      "  80101  80102  80200  80301  80302  80400  80500  80600  80700  80800\n",
      "  90100  90200  90300  90400  90500  90600  90700  90800  90900 100100\n",
      " 100200 100300 110100 110200 120100 120201 120202 120300 120400 120500\n",
      " 120600 120700 130100 130200 130300 130400 130600 130700 130803 130804\n",
      " 130805 130806 140100 140200 140300 150100 150200 150300 150400 150500\n",
      " 150600 150701 150702 150800 150900 151000 151100 151200 151300 160100\n",
      " 160200 160300 160400 160500 160600 160700 160801 160802 170100 170200\n",
      " 170300 180100 180200 180300 190100 190200 190300 200100 200200 200300\n",
      " 200400 200500 200600 200701 200702 200800 210100 210200 220100 230100\n",
      " 230200 230300 240100 240200 240300 240400 250101 250102 250103 250203\n",
      " 250204 250205 250206 250207 250301 250303 250401 250402 250500 250600\n",
      " 260101 260102 260201 260202 260203 260301 260302 260303 260401 260402\n",
      " 260403 260404 260501 260604 260605 260700 260800 260900 261000 261100\n",
      " 270101 270102 270200 270301 270302 270401 270402 270501 270502 270600\n",
      " 270701 270702 270703 270801 270802 270803 270804 270805 270901 270902\n",
      " 270903 271001 271002 271101 271102 271200 271300 271400 271501 271503\n",
      " 271600 271700 271801 271802 271900 272003 272004 272005 272006 272007\n",
      " 280101 280102 280200 280301 280302 280401 280402 280403 280404 280500\n",
      "  10000]\n"
     ]
    }
   ],
   "source": [
    "# Table: FDIC Baltimore Banks\n",
    "# Columns: Bank Name, Address(es), Census Tract\n",
    "left_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTViIZu-hbvhM3L7dIRAG95ISa7TNhUwdzlYxYzc1ygJoaYc3_scaXHe8Rtj5iwNA/pub?gid=1078028768&single=true&output=csv'\n",
    "left_col = 'Census Tract'\n",
    "\n",
    "# Table: Crosswalk Census Communities\n",
    "# 'TRACT2010', 'GEOID2010', 'CSA2010'\n",
    "right_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv'\n",
    "right_col='TRACT2010'\n",
    "\n",
    "merge_how = 'outer'\n",
    "interactive = True\n",
    "use_crosswalk = False\n",
    "\n",
    "merged_df = mergeDatasets( left_ds=left_ds, left_col=left_col, \n",
    "              right_ds=right_ds, right_col=right_col, \n",
    "              merge_how='left', interactive =True, use_crosswalk=use_crosswalk )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>Address(es)</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>TRACT2010</th>\n",
       "      <th>GEOID2010</th>\n",
       "      <th>CSA2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arundel Federal ...</td>\n",
       "      <td>333 E. Patapsco ...</td>\n",
       "      <td>250401</td>\n",
       "      <td>250401.0</td>\n",
       "      <td>2.45e+10</td>\n",
       "      <td>Brooklyn/Curtis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bank of America,...</td>\n",
       "      <td>20 N Howard St</td>\n",
       "      <td>40100</td>\n",
       "      <td>40100.0</td>\n",
       "      <td>2.45e+10</td>\n",
       "      <td>Downtown/Seton Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100 S Charles St...</td>\n",
       "      <td>40100</td>\n",
       "      <td>40100.0</td>\n",
       "      <td>2.45e+10</td>\n",
       "      <td>Downtown/Seton Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1046 Light St</td>\n",
       "      <td>230200</td>\n",
       "      <td>230200.0</td>\n",
       "      <td>2.45e+10</td>\n",
       "      <td>Inner Harbor/Fed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1800 E Monument St</td>\n",
       "      <td>70400</td>\n",
       "      <td>70400.0</td>\n",
       "      <td>2.45e+10</td>\n",
       "      <td>Oldtown/Middle East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bank Name          Address(es)  Census Tract  TRACT2010  GEOID2010              CSA2010\n",
       "0  Arundel Federal ...  333 E. Patapsco ...        250401   250401.0   2.45e+10  Brooklyn/Curtis ...\n",
       "1  Bank of America,...       20 N Howard St         40100    40100.0   2.45e+10  Downtown/Seton Hill\n",
       "3                  NaN  100 S Charles St...         40100    40100.0   2.45e+10  Downtown/Seton Hill\n",
       "4                  NaN        1046 Light St        230200   230200.0   2.45e+10  Inner Harbor/Fed...\n",
       "5                  NaN   1800 E Monument St         70400    70400.0   2.45e+10  Oldtown/Middle East"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.5 ) Get CSA and Geometry with a Crosswalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Table\n",
    "# Description: I created a public dataset from a google xlsx sheet 'Bank Addresses and Census Tract' from a workbook of the same name.\n",
    "# Table: FDIC Baltimore Banks\n",
    "# Columns: Bank Name, Address(es), Census Tract\n",
    "left_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTViIZu-hbvhM3L7dIRAG95ISa7TNhUwdzlYxYzc1ygJoaYc3_scaXHe8Rtj5iwNA/pub?gid=1078028768&single=true&output=csv'\n",
    "left_col = 'Census Tract'\n",
    "\n",
    "# Alternate Primary Table\n",
    "# Description: Same workbook, different Sheet: 'Branches per tract' \n",
    "# Columns: Census Tract, Number branches per tract\n",
    "# left_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vSHFrRSHva1f82ZQ7Uxwf3A1phqljj1oa2duGlZDM1vLtrm1GI5yHmpVX2ilTfMHQ/pub?gid=1698745725&single=true&output=csv'\n",
    "# lef_col = 'Number branches per tract'\n",
    "\n",
    "# Crosswalk Table\n",
    "# Table: Crosswalk Census Communities\n",
    "# 'TRACT2010', 'GEOID2010', 'CSA2010'\n",
    "crosswalk_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv'\n",
    "use_crosswalk = True\n",
    "crosswalk_left_col = 'TRACT2010'\n",
    "crosswalk_right_col = 'GEOID2010'\n",
    "\n",
    "# Secondary Table\n",
    "# Table: Baltimore Boundaries\n",
    "# 'TRACTCE10', 'GEOID10', 'CSA', 'NAME10', 'Tract', 'geometry'\n",
    "right_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8xXdUaT17jkdK0MWTJpg3GOy6jMWeaXTlguXNjCSb8Vr_FanSZQRaTU-m811fQz4kyMFK5wcahMNY/pub?gid=886223646&single=true&output=csv'\n",
    "right_col ='GEOID10'\n",
    "\n",
    "merge_how = 'geometry'\n",
    "interactive = True\n",
    "merge_how = 'outer'\n",
    "\n",
    "merged_df = mergeDatasets( left_ds=left_ds, left_col=left_col, \n",
    "              use_crosswalk=use_crosswalk, crosswalk_ds=crosswalk_ds,\n",
    "              crosswalk_left_col = crosswalk_left_col, crosswalk_right_col = crosswalk_right_col,\n",
    "              right_ds=right_ds, right_col=right_col, \n",
    "              merge_how=merge_how, interactive = interactive )\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can save the data so that it may be used in later tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'test_save_data_with_geom_and_csa'\n",
    "merged_df.to_csv(string+'.csv', encoding=\"utf-8\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Download data by: \n",
    "\n",
    "- Clicking the 'Files' tab in the left hand menu of this screen. Locate your file within the file explorer that appears directly under the 'Files' tab button once clicked. Right click the file in the file explorer and select the 'download' option from the dropdown.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the next tutorial you will learn how to load this data as a geospatial dataset so that it may be mapped and mapping functionalities may be applied to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can upload this data into the next tutorial in one of two ways.\n",
    "\n",
    "1) \n",
    "- uploading the saved file to google Drive and connecting to your drive path\n",
    "\n",
    "OR. \n",
    "\n",
    "2) \n",
    "- 'by first downloading the dataset as directed above, and then navigating to the next tutorial. Go to their page and:\n",
    "- Uploading data using an file 'upload' button accessible within the 'Files' tab in the left hand menu of this screen. The next tutorial will teach you how to load this data so that it may be mapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the prompts come up input the values not included from Interactive Example 1 and you will get the same output.\n",
    "# This is to demonstrate that not all parameters must be known prior to executing the function.\n",
    "\n",
    "mergeDatasets( left_ds=left_ds, left_col=left_col, right_ds=right_ds, interactive =True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDataset = mergeDatasets( left_ds=left_ds, left_col=left_col, use_crosswalk=use_crosswalk, right_ds=right_ds, right_col=right_col, merge_how = merge_how, interactive = interactive )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bank Name        object\n",
       "Address(es)      object\n",
       "Census Tract    float64\n",
       "TRACTCE10       float64\n",
       "GEOID10         float64\n",
       "NAME10          float64\n",
       "CSA              object\n",
       "Tract           float64\n",
       "geometry         object\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedDataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Run Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDatasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preconfigured Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census Crosswalk\n",
    "# 'TRACT2010', 'GEOID2010', 'CSA2010'\n",
    "left_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv'\n",
    "\n",
    "# Baltimore Boundaries\n",
    "# 'TRACTCE10', 'GEOID10', 'CSA', 'NAME10', 'Tract', 'geometry'\n",
    "right_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8xXdUaT17jkdK0MWTJpg3GOy6jMWeaXTlguXNjCSb8Vr_FanSZQRaTU-m811fQz4kyMFK5wcahMNY/pub?gid=886223646&single=true&output=csv'\n",
    "# The Left DS Cols will map to the first three Right DS Cols listed\n",
    "left_col = 'GEOID2010'\n",
    "right_col = 'GEOID10'\n",
    "merge_how = 'outer'\n",
    "interactive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDatasets( left_ds=left_ds, left_col=left_col, right_ds=right_ds, right_col=right_col, merge_how = merge_how, interactive = interactive )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
